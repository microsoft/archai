{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4bd875c",
   "metadata": {},
   "source": [
    "## Discrete Search Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5cdb0135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from overrides import overrides\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Optional\n",
    "from archai.discrete_search import ArchaiModel, DiscreteSearchSpace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e2ca76",
   "metadata": {},
   "source": [
    "Discrete search spaces in Archai are defined using the `DiscreteSearchSpace` abstract class:\n",
    "\n",
    "```python\n",
    "\n",
    "class DiscreteSearchSpace(EnforceOverrides):\n",
    "\n",
    "    @abstractmethod\n",
    "    def random_sample(self) -> ArchaiModel:\n",
    "        ...\n",
    "        \n",
    "    @abstractmethod\n",
    "    def save_arch(self, model: ArchaiModel, path: str) -> None:\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_arch(self, path: str) -> ArchaiModel:\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_model_weights(self, model: ArchaiModel, path: str) -> None:\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_model_weights(self, model: ArchaiModel, path: str) -> None:\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1d6f94",
   "metadata": {},
   "source": [
    "### CNN Search Space Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fb59c3",
   "metadata": {},
   "source": [
    "Let's start with a simple search space for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3145b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, nb_layers: int = 5, kernel_size: int = 3, hidden_dim: int = 32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.nb_layers = nb_layers\n",
    "        self.kernel_size = kernel_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        layer_list = []\n",
    "\n",
    "        for i in range(nb_layers):\n",
    "            in_ch = (3 if i == 0 else hidden_dim)\n",
    "            \n",
    "            layer_list += [\n",
    "                nn.Conv2d(in_ch, hidden_dim, kernel_size=kernel_size, padding='same'),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU()\n",
    "            ]\n",
    "\n",
    "        layer_list += [\n",
    "            nn.Conv2d(hidden_dim, 1, kernel_size=1, padding='same'),\n",
    "            nn.Sigmoid()\n",
    "        ]\n",
    "        \n",
    "        self.model = nn.Sequential(*layer_list)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def get_archid(self):\n",
    "        return f'({self.nb_layers}, {self.kernel_size}, {self.hidden_dim})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ccc4d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MyModel(nb_layers=1)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e4bd63f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(1, 3, 32)'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get_archid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa42080d",
   "metadata": {},
   "source": [
    "Let's overide DiscreteSearchSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "193ea617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Tuple\n",
    "from random import Random\n",
    "\n",
    "class CNNSearchSpace(DiscreteSearchSpace):\n",
    "    def __init__(self, min_layers: int = 1, max_layers: int = 12,\n",
    "                 kernel_list=(1, 3, 5, 7), hidden_list=(16, 32, 64, 128),\n",
    "                 seed: int = 1):\n",
    "\n",
    "        self.min_layers = min_layers\n",
    "        self.max_layers = max_layers\n",
    "        self.kernel_list = kernel_list\n",
    "        self.hidden_list = hidden_list\n",
    "        \n",
    "        self.rng = Random(seed)\n",
    "        \n",
    "    @overrides\n",
    "    def random_sample(self) -> ArchaiModel:\n",
    "        # Randomly chooses architecture parameters\n",
    "        nb_layers = self.rng.randint(self.min_layers, self.max_layers)\n",
    "        kernel_size = self.rng.choice(self.kernel_list)\n",
    "        hidden_dim = self.rng.choice(self.hidden_list)\n",
    "        \n",
    "        model = MyModel(nb_layers, kernel_size, hidden_dim)\n",
    "        \n",
    "        # Wraps model into ArchaiModel\n",
    "        return ArchaiModel(arch=model, archid=model.get_archid())\n",
    "\n",
    "    @overrides\n",
    "    def save_arch(self, model: ArchaiModel, file: str):\n",
    "        with open(file, 'w') as fp:\n",
    "            json.dump({\n",
    "                'nb_layers': model.arch.nb_layers,\n",
    "                'kernel_size': model.arch.kernel_size,\n",
    "                'hidden_dim': model.arch.hidden_dim\n",
    "            }, fp)\n",
    "\n",
    "    @overrides\n",
    "    def load_arch(self, file: str):\n",
    "        config = json.load(open(file))\n",
    "        model = MyModel(**config)\n",
    "        \n",
    "        return ArchaiModel(arch=model, archid=model.get_archid())\n",
    "\n",
    "    @overrides\n",
    "    def save_model_weights(self, model: ArchaiModel, file: str):\n",
    "        state_dict = model.arch.get_state_dict()\n",
    "        torch.save(state_dict, file)\n",
    "    \n",
    "    @overrides\n",
    "    def load_model_weights(self, model: ArchaiModel, file: str):\n",
    "        model.arch.load_state_dict(torch.load(file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7db02619",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = CNNSearchSpace(hidden_list=[32, 64, 128])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce23725",
   "metadata": {},
   "source": [
    "Sampling a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83c03fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArchaiModel(\n",
       "\tarchid=(3, 1, 64), \n",
       "\tmetadata={}, \n",
       "\tarch=MyModel(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (10): Sigmoid()\n",
       "  )\n",
       ")\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = ss.random_sample()\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619c4d9c",
   "metadata": {},
   "source": [
    "Saving an architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3dace5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.save_arch(m, 'arch.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1d4dba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"nb_layers\": 3, \"kernel_size\": 1, \"hidden_dim\": 64}"
     ]
    }
   ],
   "source": [
    "!cat arch.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70813cc7",
   "metadata": {},
   "source": [
    "Loading an architecture (not the weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "863ef766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArchaiModel(\n",
       "\tarchid=(3, 1, 64), \n",
       "\tmetadata={}, \n",
       "\tarch=MyModel(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (10): Sigmoid()\n",
       "  )\n",
       ")\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.load_arch('arch.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c0b5a3",
   "metadata": {},
   "source": [
    "### Making the search space compatible with different types of algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4083db69",
   "metadata": {},
   "source": [
    "* Evolutionary-based algorithms:\n",
    " - User must subclass `EvolutionarySearchSpace` and implement `EvolutionarySearchSpace.mutate` and `EvolutionarySearchSpace.crossover`\n",
    "\n",
    "\n",
    "* BO-based algorithms:\n",
    " - User must subclass `BayesOptSearchSpace` and override `BayesOptSearchSpace.encode`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d294ab69",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "78b73a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from archai.discrete_search import EvolutionarySearchSpace, BayesOptSearchSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0e02255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNSearchSpaceExt(CNNSearchSpace, EvolutionarySearchSpace, BayesOptSearchSpace):\n",
    "    ''' We are subclassing CNNSearchSpace just to save up space'''\n",
    "    \n",
    "    @overrides\n",
    "    def mutate(self, model_1: ArchaiModel) -> ArchaiModel:\n",
    "        config = {\n",
    "            'nb_layers': model_1.arch.nb_layers,\n",
    "            'kernel_size': model_1.arch.kernel_size,\n",
    "            'hidden_dim': model_1.arch.hidden_dim\n",
    "        }\n",
    "        \n",
    "        if self.rng.random() < 0.2:\n",
    "            config['nb_layers'] = self.rng.randint(self.min_layers, self.max_layers)\n",
    "        \n",
    "        if self.rng.random() < 0.2:\n",
    "            config['kernel_size'] = self.rng.choice(self.kernel_list)\n",
    "        \n",
    "        if self.rng.random() < 0.2:\n",
    "            config['hidden_dim'] = self.rng.choice(self.hidden_list)\n",
    "        \n",
    "        mutated_model = MyModel(**config)\n",
    "        \n",
    "        return ArchaiModel(\n",
    "            arch=mutated_model, archid=mutated_model.get_archid()\n",
    "        )\n",
    "    \n",
    "    @overrides\n",
    "    def crossover(self, model_list: List[ArchaiModel]) -> ArchaiModel:\n",
    "        model_1, model_2 = model_list[:2]\n",
    "        \n",
    "        new_config = {\n",
    "            'nb_layers': self.rng.choice([model_1.arch.nb_layers, model_2.arch.nb_layers]),\n",
    "            'kernel_size': self.rng.choice([model_1.arch.kernel_size, model_2.arch.kernel_size]),\n",
    "            'hidden_dim': self.rng.choice([model_1.arch.hidden_dim, model_2.arch.hidden_dim]),\n",
    "        }\n",
    "        \n",
    "        crossover_model = MyModel(**new_config)\n",
    "        \n",
    "        return ArchaiModel(\n",
    "            arch=crossover_model, archid=crossover_model.get_archid()\n",
    "        )\n",
    "    \n",
    "    @overrides\n",
    "    def encode(self, model: ArchaiModel) -> np.ndarray:\n",
    "        return np.array([model.arch.nb_layers, model.arch.kernel_size, model.arch.hidden_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8f9b6ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = CNNSearchSpaceExt(hidden_list=[32, 64, 128])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7582b266",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d23e6373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(3, 1, 64)'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = ss.random_sample()\n",
    "m.archid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6c695837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(8, 1, 64)'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.mutate(m).archid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e0b99677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  1, 64])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.encode(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1201e318",
   "metadata": {},
   "source": [
    "Now `CNNSearchSpaceExt` is compatible with Bayesian Optimization and Evolutionary based search algorithms!\n",
    "\n",
    "**To see a list of built-in search spaces, go to `archai/discrete_search/search_spaces`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad0c69",
   "metadata": {},
   "source": [
    "Example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0ce94672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArchaiModel(\n",
       "\tarchid=74f66612a0d01c5b7d4702234756b0ee4ffa5abc_64_64, \n",
       "\tmetadata={'parent': '32fa5956ab3ce9e05bc42836599a8dc9dd53e847_64_64'}, \n",
       "\tarch=SegmentationDagModel(\n",
       "  (edge_dict): ModuleDict(\n",
       "    (input-output): Block(\n",
       "      (op): Sequential(\n",
       "        (0): NormalConvBlock(\n",
       "          (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stem_block): NormalConvBlock(\n",
       "    (conv): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (up): Upsample(size=(64, 64), mode=nearest)\n",
       "  (post_upsample): Sequential(\n",
       "    (0): NormalConvBlock(\n",
       "      (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): NormalConvBlock(\n",
       "      (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): NormalConvBlock(\n",
       "      (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Conv2d(40, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from archai.discrete_search.search_spaces.segmentation_dag.search_space import SegmentationDagSearchSpace\n",
    "\n",
    "ss = SegmentationDagSearchSpace(nb_classes=1, img_size=(64, 64), max_layers=3)\n",
    "ss.mutate(ss.random_sample())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
