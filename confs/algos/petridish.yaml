# Use darts defaults
__include__: "darts.yaml"

common:
  # yaml_log: False
  apex:
    ray:
      # Initialize ray, but note that ray cannot be used if apex distributed is enabled
      enabled: True
      # If True ray will run in serial mode
      local_mode: False

nas:
  eval:
    final_desc_foldername: "$expdir/model_desc_gallery"
    model_desc:
      # Number of reductions to be applied
      n_reductions: 2
      # Number of maximum cells
      # For pareto frontier, we use cell_count_scale to  multiply cells and limit by n_cells
      n_cells: 20
      # Weight for loss from auxiliary towers in test time arch
      aux_weight: 0.4
      # Number of edges that each node will take inputs from
      num_edges_to_sample: 2
      model_stems:
        # Number of input/output channels for nodes in 1st cell
        init_node_ch: 36
      cell:
        # Number of nodes in a cell if template desc is not provided
        n_nodes: 5
        cell_post_op: "proj_channels"
    petridish:
      # For eval first multiply number of cells used in search by this factor, limit to n_cells
      cell_count_scale: 1.0
    trainer:
      epochs: 600
  search:
    # Gallery of models that eval will train from scratch
    final_desc_foldername: "$expdir/model_desc_gallery"
    petridish:
      # Tolerance
      convex_hull_eps: 0.025
      # If any parent model reaches this many multiply-additions,
      # then the search is terminated or it reaches maximum number of parent pool_size
      max_madd: 200000000
      # If the pool of parent models reaches this size,
      # then search is terminated or if it reaches maximum multiply-adds
      max_hull_points: 100
      checkpoints_foldername: "$expdir/petridish_search_checkpoints"
    search_iters: 4
    pareto:
      max_cells: 8
      max_reductions: 3
      max_nodes: 3
      # If False then there will only be one seed model;
      # If True a number of seed models with different number of cells,
      # reductions and nodes will be used to initialize the search;
      # Note this provides more coverage of the frontier
      enabled: True
    model_desc:
      n_cells: 3
      n_reductions: 1
      # Number of edges that each node will take inputs from
      num_edges_to_sample: 2
      cell:
        n_nodes: 1
        cell_post_op: "proj_channels"
    seed_train:
      trainer:
        # Number of epochs that model will be trained before search
        epochs: 80
      loader:
        train_batch: 128
    post_train:
      trainer:
        # Number of epochs that model will be trained after search
        epochs: 80
      loader:
        train_batch: 96
    trainer:
      # Defined by original paper
      l1_alphas: 0.001
      # Number of epochs that model will be trained during search
      epochs: 80
    loader:
      train_batch: 96
      # Split portion for test set, 0 to 1
      val_ratio: 0.2
