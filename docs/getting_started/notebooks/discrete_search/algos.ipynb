{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6fa8b24",
   "metadata": {},
   "source": [
    "# Search Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b103993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from overrides import overrides\n",
    "from typing import List\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import json\n",
    "from random import Random\n",
    "\n",
    "from archai.discrete_search.api import ArchaiModel, EvolutionarySearchSpace, BayesOptSearchSpace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81488a6",
   "metadata": {},
   "source": [
    "We will re-use the CNN search space created in the [search space example](./search_space.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7ac3c7",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from search_space import MyModel, CNNSearchSpaceExt as CNNSearchSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a667bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = CNNSearchSpace(max_layers=10, kernel_list=[3, 5, 7], hidden_list=[32, 64, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b5dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ss.random_sample()\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24de6e98",
   "metadata": {},
   "source": [
    "## Dataset Provider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf68260",
   "metadata": {},
   "source": [
    "Datasets are represented in Archai throught the [`DatasetProvider`](../../reference/api/archai.discrete_search.api.rst) class. For this example, we will use the built-in dataset provider of the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc94c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from archai.datasets.cv.mnist_dataset_provider import MnistDatasetProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058373ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_provider = MnistDatasetProvider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e836d0",
   "metadata": {},
   "source": [
    "We can get train/test PyTorch datasets from a DatasetProvider by calling `dataset_provider.get_datasets(load_train, load_test, transforms_train, transforms_test)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10505074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads only the training set\n",
    "tr_d = dataset_provider.get_train_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecace173",
   "metadata": {},
   "source": [
    "## Wrapping custom evaluation code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056973d6",
   "metadata": {},
   "source": [
    "We will evaluate our models using partial trainig validation accuracy as a proxy for final task performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df253354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from archai.api.dataset_provider import DatasetProvider\n",
    "from archai.discrete_search.api import ModelEvaluator\n",
    "from archai.discrete_search.evaluators import RayParallelEvaluator\n",
    "\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "\n",
    "class PartialTrainingValAccuracy(ModelEvaluator):\n",
    "    def __init__(self, dataset: DatasetProvider, training_epochs: float = 1.0, lr: float = 1e-4, device: str = 'cpu',\n",
    "                 progress_bar: bool = False):\n",
    "        self.training_epochs = training_epochs\n",
    "        self.dataset_provider = dataset\n",
    "        self.device = device\n",
    "        self.lr = lr\n",
    "        self.progress_bar = progress_bar\n",
    "    \n",
    "    @overrides\n",
    "    def evaluate(self, model, budget = None) -> float:\n",
    "        # Loads the dataset\n",
    "        tr_data = self.dataset_provider.get_train_dataset()\n",
    "        val_data = self.dataset_provider.get_val_dataset()\n",
    "        \n",
    "        tr_dl = torch.utils.data.DataLoader(tr_data, batch_size=16, shuffle=True, num_workers=4)\n",
    "        val_dl = torch.utils.data.DataLoader(val_data, batch_size=16, shuffle=False, num_workers=4)\n",
    "        \n",
    "        # Training settings\n",
    "        optimizer = torch.optim.Adam(model.arch.parameters(), lr=self.lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        model.arch.train()\n",
    "        model.arch.to(self.device)\n",
    "        \n",
    "        # Partial training\n",
    "        epoch_iter = range(math.ceil(self.training_epochs))\n",
    "        if self.progress_bar:\n",
    "            epoch_iter = tqdm(epoch_iter, desc=f'Training model {model.archid}')\n",
    "\n",
    "        for epoch_nb in epoch_iter:\n",
    "            # Early stops for fractional values of training epochs (e.g, 0.2)\n",
    "            early_stop = len(tr_dl) + 1\n",
    "            if 0 < (self.training_epochs - epoch_nb) < 1:\n",
    "                early_stop = int((self.training_epochs - epoch_nb) * len(tr_dl))\n",
    "            \n",
    "            for i, (x, y) in enumerate(tr_dl):\n",
    "                if i >= early_stop:\n",
    "                    break\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                pred = model.arch(x.to(self.device))\n",
    "                loss = criterion(pred, y.to(self.device))\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Evaluates final model\n",
    "        model.arch.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_pred, val_target = [], []\n",
    "\n",
    "            for x, y in val_dl:\n",
    "                val_pred.append(model.arch(x.to(self.device)).argmax(axis=1).to('cpu'))\n",
    "                val_target.append(y.to('cpu'))\n",
    "\n",
    "            val_pred, val_target = torch.cat(val_pred, axis=0), torch.cat(val_target, axis=0)\n",
    "            val_acc = (val_pred.squeeze() == val_target.squeeze()).numpy().mean()\n",
    "\n",
    "        # Returns model to cpu\n",
    "        model.arch.cpu()\n",
    "        \n",
    "        return val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a74a59",
   "metadata": {},
   "source": [
    "Let's test our evaluator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e40e515",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_tr = PartialTrainingValAccuracy(\n",
    "    dataset_provider,\n",
    "    training_epochs=0.001, # Trains for 1/1000 of an epoch\n",
    "    progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689a2adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_tr.evaluate(ss.random_sample())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d6e6884",
   "metadata": {},
   "source": [
    "We can make this objective more efficient evaluating multiple architectures in parallel. To do that, we can use the `RayParallelObjective` wrapper mentioned in the [previous example](./evaluators.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88c234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_partial_tr = RayParallelEvaluator(partial_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa3c2a5",
   "metadata": {},
   "source": [
    "Let's test our partial training objective sending two random architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adfc19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "parallel_partial_tr.send(ss.random_sample())\n",
    "parallel_partial_tr.send(ss.random_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a974a2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "parallel_partial_tr.fetch_all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3b548cb",
   "metadata": {},
   "source": [
    "To run the same objective distributing jobs across multiple GPUs, just set the `num_gpus` parameter from [ray.init](https://docs.ray.io/en/latest/ray-core/package-ref.html#ray-init) and set `device='cuda'` (This assumes you have installed the NVidia CUDA SDK and PyTorch for CUDA as per the setup instructions at https://pytorch.org/get-started/locally/)\n",
    "\n",
    "```python\n",
    "RayParallelObjective(\n",
    "    PartialTrainingValAccuracy(training_epochs=1, device='cuda'),\n",
    "    num_gpus=0.5, # 2 jobs per gpu available\n",
    "    max_calls=1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c50b818",
   "metadata": {},
   "source": [
    "## Defining Search Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ac88d",
   "metadata": {},
   "source": [
    "Search optimization objectives are specified using the `archai.discrete_search.SearchObjectives` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25095dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from archai.discrete_search.api import SearchObjectives\n",
    "\n",
    "objectives = SearchObjectives()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccf6ddc3",
   "metadata": {},
   "source": [
    "### Adding objectives"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9950bb3b",
   "metadata": {},
   "source": [
    "To add search objectives, we can use the `SearchObjectives.add_objective` method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3060750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from archai.discrete_search.evaluators import AvgOnnxLatency, TorchFlops\n",
    "\n",
    "objectives.add_objective(\n",
    "    # Objective function name (will be used in plots and reports)\n",
    "    name='ONNX Latency (ms)',  \n",
    "    \n",
    "    # ModelEvaluator object that will be used to evaluate the model\n",
    "    model_evaluator=AvgOnnxLatency(input_shape=(1, 1, 28, 28), num_trials=3),  \n",
    "    \n",
    "    # Optimization direction, `True` for maximization or `False` for minimization\n",
    "    higher_is_better=False,\n",
    "\n",
    "    # Whether this objective should be considered 'compute intensive' or not.\n",
    "    compute_intensive=False \n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92aaef34",
   "metadata": {},
   "source": [
    "The `compute_intensive` flag is used in some search algorithms to help increase search efficiency. For instance, search algorithms that use surrogate models may try to estimate the value of expensive objective functions of unseen architectures in certain situations, while cheap objectives (`compute_intensive=False`) will just be computed directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd5163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectives.add_objective(\n",
    "    'FLOPs', TorchFlops(torch.randn(1, 1, 28, 28)),\n",
    "    higher_is_better=False,\n",
    "    compute_intensive=False,\n",
    "    # We may optionally add a constraint. \n",
    "    # Architectures outside this range will be ignored by the search algorithm\n",
    "    constraint=(0.0, 1e9)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41127aed",
   "metadata": {},
   "source": [
    "Additionally, objectives that are cheap to evaluate (`compute_intensive=False`) may receive an optional `constraint` argument. Model candidates outside this range will\n",
    "be ignored by the search algorithm."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b058b47",
   "metadata": {},
   "source": [
    "We can evaluate cheap objectives calling `SearchObjectives.eval_cheap_objs(model_list)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df60ad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [ss.random_sample() for _ in range(2)]\n",
    "objectives.eval_cheap_objs(samples,\n",
    "                           progress_bar=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7ae043b",
   "metadata": {},
   "source": [
    "We can check if a model satisfies the constraints we added for the FLOPs objective by calling `SearchObjectives.validate_constraints(model_list)` or `SearchObjectives.is_model_valid(ss.random_sample())`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99203fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ss.random_sample()\n",
    "\n",
    "objectives.validate_constraints([m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a3966",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectives.is_model_valid(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddc2911",
   "metadata": {},
   "source": [
    "By default, all objective and constraints evaluations are cached to prevent spending resources in the same architecture twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3893e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The evaluation cache is built using the\n",
    "# tuple (obj_name, archid, budget)\n",
    "objectives.lookup_cache('FLOPs', samples[0].archid, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbcc6c7",
   "metadata": {},
   "source": [
    "Caching can be disabled setting `SearchObjectives(cache_objective_evaluation=False)`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee596afe",
   "metadata": {},
   "source": [
    "Now, let's try adding the partial training objective we created before. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "The code below requires a GPU compatible with CUDA. If running on CPU, make sure to change `device='cuda'` to `device='cpu'` and set the `num_cpus` parameter for `RayParallelEvaluator` accordingly.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c463da",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectives.add_objective(\n",
    "    'Partial training Validation Accuracy (1 epoch)',\n",
    "    RayParallelEvaluator(\n",
    "        PartialTrainingValAccuracy(dataset_provider, training_epochs=1, device='cuda'),\n",
    "        num_gpus=0.5, # 2 jobs per gpu available\n",
    "        max_calls=1\n",
    "    ),\n",
    "    higher_is_better=True,\n",
    "    compute_intensive=True # This is a compute intensive evaluator\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33bfae1a",
   "metadata": {},
   "source": [
    "Expensive objectives can be evaluated using `SearchObjectives.eval_expensive_objs(model_list)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ec34f6",
   "metadata": {},
   "source": [
    "Alternatively, all objectives (expensive and cheap) can also be evaluated using `SearchObjectives.eval_all_objs`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91205ae4",
   "metadata": {},
   "source": [
    "### Adding extra constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0e1653",
   "metadata": {},
   "source": [
    "Besides the constraint parameter from cheap objectives, it is also possible to add extra constraints that are not search objectives (and thus should not be optimized by NAS algorithms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cf95ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from archai.discrete_search.evaluators import TorchNumParameters\n",
    "\n",
    "objectives.add_constraint(\n",
    "    'Number of parameters',\n",
    "    TorchNumParameters(),\n",
    "    constraint=(0.0, 1e6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc36366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectives.validate_constraints([m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a83b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectives.is_model_valid(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8bd85d",
   "metadata": {},
   "source": [
    "## Using a search algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2a8fa7",
   "metadata": {},
   "source": [
    "Now that we know how to create and use search objectives, we can finally use a search algorithm do to Neural Architecture Search!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457800f2",
   "metadata": {},
   "source": [
    "### Example: `EvolutionParetoSearch`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b60964",
   "metadata": {},
   "source": [
    "Let's start with an evolutionary-based search algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b66c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from archai.discrete_search.algos import EvolutionParetoSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = EvolutionParetoSearch(\n",
    "    ss, objectives, \n",
    "    output_dir='./out_evo',\n",
    "    num_iters=5, num_crossovers=5,\n",
    "    mutations_per_parent=2,\n",
    "    max_unseen_population=10,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0d4117",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "search_results = algo.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44658a70",
   "metadata": {},
   "source": [
    "By default all algorithms will save the final pareto architectures `{output_dir}/pareto_models_iter_*/`, pareto evolution plots `pareto_*.png` and search state tables with all the results `{output_dir}/search_state_*.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248462b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "os.listdir('./out_evo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384e9a76",
   "metadata": {},
   "source": [
    "It is also possible to get information from the `search_results` object directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2923ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "search_results.plot_2d_pareto_evolution(('ONNX Latency (ms)', 'Partial training Validation Accuracy (1 epoch)'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0484398e",
   "metadata": {},
   "source": [
    "We can get `pandas.DataFrame` object with the search results calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d6df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "results_df = search_results.get_search_state_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e9c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "results_df.query('is_pareto').sort_values('Partial training Validation Accuracy (1 epoch)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364fdfd0",
   "metadata": {},
   "source": [
    "Since our search space is also compatible with Bayesian Optimization algorithms, let's try more sophisticated algorithm like MO-BANANAS. \n",
    "\n",
    "MO-BANANAS will progressively train a surrogate model based on the data gathered during search. This surrogate model will be used to predict the result of expensive objective function evaluations and will try to determine what are the best possible architectures according to the surrogate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6617b53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from archai.discrete_search.algos import MoBananasSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db035881",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo2 = MoBananasSearch(\n",
    "    ss, objectives, \n",
    "    output_dir='./out_bananas', \n",
    "    num_iters=5, mutations_per_parent=5,\n",
    "    num_candidates=20,\n",
    "    seed=43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b0279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "search_results2 = algo2.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90c31a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "os.listdir('./out_bananas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d165b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "search_results2.plot_2d_pareto_evolution(('ONNX Latency (ms)', 'Partial training Validation Accuracy (1 epoch)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2df08e8",
   "metadata": {},
   "source": [
    "MO-BANANAS will also save the predictive mean and variance of the expensive objectives during that iteration ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bbcc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "results_df2 = search_results2.get_search_state_df()\n",
    "results_df2.query('is_pareto').sort_values('Partial training Validation Accuracy (1 epoch)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6f69151",
   "metadata": {},
   "source": [
    "Let's use [plotly](https://plotly.com/) to compare the final pareto frontiers of both algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c43a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "merged_results_df = pd.concat([\n",
    "    results_df.assign(algo='Evolution Pareto'),\n",
    "    results_df2.assign(algo='Mo-BANANAS')\n",
    "], axis=0)\n",
    "\n",
    "fig = px.scatter(\n",
    "    merged_results_df.query('is_pareto'), \n",
    "    'ONNX Latency (ms)', \n",
    "    'Partial training Validation Accuracy (1 epoch)',\n",
    "    hover_name='archid',\n",
    "    color='algo',\n",
    "    facet_col='algo'\n",
    ")\n",
    "\n",
    "fig.layout = fig.layout.update(showlegend=False)\n",
    "fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8975ca6b",
   "metadata": {},
   "source": [
    "In this particular example both algorithms found similar pareto frontiers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "archai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b2be478cf8a2d9a6a1293b022e8589530f7ec0d0340a3a36da6068ef3d344086"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
