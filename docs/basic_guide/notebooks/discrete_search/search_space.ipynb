{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4bd875c",
   "metadata": {},
   "source": [
    "# Discrete Search Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cdb0135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from overrides import overrides\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Optional\n",
    "from archai.discrete_search import ArchaiModel, DiscreteSearchSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d100fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16149883",
   "metadata": {},
   "source": [
    "## The `ArchaiModel` class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb4c0081",
   "metadata": {},
   "source": [
    "The `ArchaiModel` class is a base class used to wrap all model objects. `ArchaiModel` also stores an architecture ID (`ArchaiModel.archid`) and optionally a metadata dictionary (`ArchaiModel.metadata`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7f4686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from archai.discrete_search import ArchaiModel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f563253",
   "metadata": {},
   "source": [
    "Let's first consider a simple PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5fe6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, nb_layers: int = 5, kernel_size: int = 3, hidden_dim: int = 32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.nb_layers = nb_layers\n",
    "        self.kernel_size = kernel_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        layer_list = []\n",
    "\n",
    "        for i in range(nb_layers):\n",
    "            in_ch = (3 if i == 0 else hidden_dim)\n",
    "            \n",
    "            layer_list += [\n",
    "                nn.Conv2d(in_ch, hidden_dim, kernel_size=kernel_size, padding='same'),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU()\n",
    "            ]\n",
    "\n",
    "        layer_list += [\n",
    "            nn.Conv2d(hidden_dim, 1, kernel_size=1, padding='same'),\n",
    "            nn.Sigmoid()\n",
    "        ]\n",
    "        \n",
    "        self.model = nn.Sequential(*layer_list)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bb34bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj = MyModel(nb_layers=2, kernel_size=3, hidden_dim=16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4dfe5ad",
   "metadata": {},
   "source": [
    "We can now wrap a `DummyModel` instance into an `ArchaiModel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "290e625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ArchaiModel(\n",
    "    arch=model_obj,\n",
    "    archid=f'L={model_obj.nb_layers}, K={model_obj.kernel_size}, H={model_obj.hidden_dim}',\n",
    "    metadata={'optional': {'metadata'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a61e5264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L=2, K=3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.archid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0ea6fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optional': {'metadata'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2337eb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyModel(\n",
       "  (layers): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.arch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5732d030",
   "metadata": {},
   "source": [
    "Architecture ids are used to identify and deduplicate architectures during search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b1d6f94",
   "metadata": {},
   "source": [
    "## Building a Search Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e2ca76",
   "metadata": {},
   "source": [
    "Discrete search spaces in Archai are defined using the `DiscreteSearchSpace` abstract class:\n",
    "\n",
    "```python\n",
    "\n",
    "class DiscreteSearchSpace(EnforceOverrides):\n",
    "\n",
    "    @abstractmethod\n",
    "    def random_sample(self) -> ArchaiModel:\n",
    "        ...\n",
    "        \n",
    "    @abstractmethod\n",
    "    def save_arch(self, model: ArchaiModel, path: str) -> None:\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_arch(self, path: str) -> ArchaiModel:\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_model_weights(self, model: ArchaiModel, path: str) -> None:\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_model_weights(self, model: ArchaiModel, path: str) -> None:\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa42080d",
   "metadata": {},
   "source": [
    "To turn `MyModel` into a search space, we need to override the `DiscreteSearchSpace` abstract base class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "193ea617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Tuple\n",
    "from random import Random\n",
    "\n",
    "class CNNSearchSpace(DiscreteSearchSpace):\n",
    "    def __init__(self, min_layers: int = 1, max_layers: int = 12,\n",
    "                 kernel_list=(1, 3, 5, 7), hidden_list=(16, 32, 64, 128),\n",
    "                 seed: int = 1):\n",
    "\n",
    "        self.min_layers = min_layers\n",
    "        self.max_layers = max_layers\n",
    "        self.kernel_list = kernel_list\n",
    "        self.hidden_list = hidden_list\n",
    "        \n",
    "        self.rng = Random(seed)\n",
    "    \n",
    "    def get_archid(self, model: MyModel) -> str:\n",
    "        return f'L={model.nb_layers}, K={model.kernel_size}, H={model.hidden_dim}'\n",
    "\n",
    "    @overrides\n",
    "    def random_sample(self) -> ArchaiModel:\n",
    "        # Randomly chooses architecture parameters\n",
    "        nb_layers = self.rng.randint(self.min_layers, self.max_layers)\n",
    "        kernel_size = self.rng.choice(self.kernel_list)\n",
    "        hidden_dim = self.rng.choice(self.hidden_list)\n",
    "        \n",
    "        model = MyModel(nb_layers, kernel_size, hidden_dim)\n",
    "        \n",
    "        # Wraps model into ArchaiModel\n",
    "        return ArchaiModel(arch=model, archid=self.get_archid(model))\n",
    "\n",
    "    @overrides\n",
    "    def save_arch(self, model: ArchaiModel, file: str):\n",
    "        with open(file, 'w') as fp:\n",
    "            json.dump({\n",
    "                'nb_layers': model.arch.nb_layers,\n",
    "                'kernel_size': model.arch.kernel_size,\n",
    "                'hidden_dim': model.arch.hidden_dim\n",
    "            }, fp)\n",
    "\n",
    "    @overrides\n",
    "    def load_arch(self, file: str):\n",
    "        config = json.load(open(file))\n",
    "        model = MyModel(**config)\n",
    "        \n",
    "        return ArchaiModel(arch=model, archid=self.get_archid(model))\n",
    "\n",
    "    @overrides\n",
    "    def save_model_weights(self, model: ArchaiModel, file: str):\n",
    "        state_dict = model.arch.get_state_dict()\n",
    "        torch.save(state_dict, file)\n",
    "    \n",
    "    @overrides\n",
    "    def load_model_weights(self, model: ArchaiModel, file: str):\n",
    "        model.arch.load_state_dict(torch.load(file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7db02619",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = CNNSearchSpace(hidden_list=[32, 64, 128])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ce23725",
   "metadata": {},
   "source": [
    "Let's try sampling an architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83c03fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArchaiModel(\n",
       "\tarchid=(3, 1, 64), \n",
       "\tmetadata={}, \n",
       "\tarch=MyModel(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (10): Sigmoid()\n",
       "  )\n",
       ")\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = ss.random_sample()\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619c4d9c",
   "metadata": {},
   "source": [
    "Saving an architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dace5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.save_arch(m, 'arch.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1d4dba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"nb_layers\": 3, \"kernel_size\": 1, \"hidden_dim\": 64}"
     ]
    }
   ],
   "source": [
    "!cat arch.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70813cc7",
   "metadata": {},
   "source": [
    "Loading an architecture without the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "863ef766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArchaiModel(\n",
       "\tarchid=(3, 1, 64), \n",
       "\tmetadata={}, \n",
       "\tarch=MyModel(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (10): Sigmoid()\n",
       "  )\n",
       ")\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.load_arch('arch.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5c0b5a3",
   "metadata": {},
   "source": [
    "## Making the search space compatible with NAS algorithms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de4594c0",
   "metadata": {},
   "source": [
    "Search spaces serve as the main interface between NAS algorithms and the application. Different classes of NAS algorithms interact with architectures from the search space using specific abstract classes:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4083db69",
   "metadata": {},
   "source": [
    "\n",
    "##### Evolutionary algorithms:\n",
    " - User must subclass `EvolutionarySearchSpace` and implement `EvolutionarySearchSpace.mutate` and `EvolutionarySearchSpace.crossover`\n",
    "\n",
    "##### Bayesian Optimization algorithms:\n",
    " - User must subclass `BayesOptSearchSpace` and override `BayesOptSearchSpace.encode`\n",
    " - Encode should take an `ArchaiModel` and produce a fixed-length vector representation of that architecture. This numerical representation will be used to train surrogate models.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d294ab69",
   "metadata": {},
   "source": [
    "#### Example: Making `CNNSearchSpace` compatible with NAS algorithsm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "006a0dae",
   "metadata": {},
   "source": [
    "Let's make our search space compatible with Evolutionary and Bayesian Optimization NAS algorithms. To do that, we need to subclass `EvolutionarySearchSpace` and `BayesOptSearchSpace`, and implement `mutation`, `crossover` and `encode` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e02255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from archai.discrete_search import EvolutionarySearchSpace, BayesOptSearchSpace\n",
    "\n",
    "class CNNSearchSpaceExt(CNNSearchSpace, EvolutionarySearchSpace, BayesOptSearchSpace):\n",
    "    ''' We are subclassing CNNSearchSpace just to save up space'''\n",
    "    \n",
    "    @overrides\n",
    "    def mutate(self, model_1: ArchaiModel) -> ArchaiModel:\n",
    "        config = {\n",
    "            'nb_layers': model_1.arch.nb_layers,\n",
    "            'kernel_size': model_1.arch.kernel_size,\n",
    "            'hidden_dim': model_1.arch.hidden_dim\n",
    "        }\n",
    "        \n",
    "        if self.rng.random() < 0.2:\n",
    "            config['nb_layers'] = self.rng.randint(self.min_layers, self.max_layers)\n",
    "        \n",
    "        if self.rng.random() < 0.2:\n",
    "            config['kernel_size'] = self.rng.choice(self.kernel_list)\n",
    "        \n",
    "        if self.rng.random() < 0.2:\n",
    "            config['hidden_dim'] = self.rng.choice(self.hidden_list)\n",
    "        \n",
    "        mutated_model = MyModel(**config)\n",
    "        \n",
    "        return ArchaiModel(\n",
    "            arch=mutated_model, archid=self.get_archid(mutated_model)\n",
    "        )\n",
    "    \n",
    "    @overrides\n",
    "    def crossover(self, model_list: List[ArchaiModel]) -> ArchaiModel:\n",
    "        model_1, model_2 = model_list[:2]\n",
    "        \n",
    "        new_config = {\n",
    "            'nb_layers': self.rng.choice([model_1.arch.nb_layers, model_2.arch.nb_layers]),\n",
    "            'kernel_size': self.rng.choice([model_1.arch.kernel_size, model_2.arch.kernel_size]),\n",
    "            'hidden_dim': self.rng.choice([model_1.arch.hidden_dim, model_2.arch.hidden_dim]),\n",
    "        }\n",
    "        \n",
    "        crossover_model = MyModel(**new_config)\n",
    "        \n",
    "        return ArchaiModel(\n",
    "            arch=crossover_model, archid=self.get_archid(crossover_model)\n",
    "        )\n",
    "    \n",
    "    @overrides\n",
    "    def encode(self, model: ArchaiModel) -> np.ndarray:\n",
    "        return np.array([model.arch.nb_layers, model.arch.kernel_size, model.arch.hidden_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f9b6ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = CNNSearchSpaceExt(hidden_list=[32, 64, 128])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7582b266",
   "metadata": {},
   "source": [
    "Now we can generate mutations, crossover and encodings from any architecture of this search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d23e6373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(3, 1, 64)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = ss.random_sample()\n",
    "m.archid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c695837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(8, 1, 64)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.mutate(m).archid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0b99677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  1, 64])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.encode(m)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1201e318",
   "metadata": {},
   "source": [
    "Now we can use `CNNSearchSpaceExt` with EA and BO search algorithms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d638e189",
   "metadata": {},
   "source": [
    "## Built-in Search Spaces"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6439c2b3",
   "metadata": {},
   "source": [
    "Instead of creating a search space from scratch, Archai has a list of built-in search spaces that can be used for multiple tasks. A list of built-in search spaces can be found in `archai/discrete_search/search_spaces`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fad0c69",
   "metadata": {},
   "source": [
    "Example: Semantic Segmentation Search Space (`SegmentationDagSearchSpace`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ce94672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArchaiModel(\n",
       "\tarchid=74f66612a0d01c5b7d4702234756b0ee4ffa5abc_64_64, \n",
       "\tmetadata={'parent': '32fa5956ab3ce9e05bc42836599a8dc9dd53e847_64_64'}, \n",
       "\tarch=SegmentationDagModel(\n",
       "  (edge_dict): ModuleDict(\n",
       "    (input-output): Block(\n",
       "      (op): Sequential(\n",
       "        (0): NormalConvBlock(\n",
       "          (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stem_block): NormalConvBlock(\n",
       "    (conv): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (up): Upsample(size=(64, 64), mode=nearest)\n",
       "  (post_upsample): Sequential(\n",
       "    (0): NormalConvBlock(\n",
       "      (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): NormalConvBlock(\n",
       "      (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): NormalConvBlock(\n",
       "      (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Conv2d(40, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from archai.discrete_search.search_spaces.segmentation_dag.search_space import SegmentationDagSearchSpace\n",
    "\n",
    "ss = SegmentationDagSearchSpace(nb_classes=1, img_size=(64, 64), max_layers=3)\n",
    "ss.mutate(ss.random_sample())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('archai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b2be478cf8a2d9a6a1293b022e8589530f7ec0d0340a3a36da6068ef3d344086"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
